{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "# df = pd.read_csv(\"teste.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['ID Aluno']==208149] #id\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "primeiroCiC = ['116301', '118001', '118010', '113034', '140481', '145971']\n",
    "segundoCiC = ['116319', '115045', '118028', '118036', '113042']\n",
    "terceiroCiC = ['118044', '118052', '113956', '113051', '117366']\n",
    "\n",
    "\n",
    "primeiroLic1 =['116793', '117366', '145971', '147389', '194221']\n",
    "segundoLic1 = ['113034', '116301', '125156']\n",
    "terceiroLic1 = ['115045', '116319', '125172']\n",
    "\n",
    "primeiroLic2 =['113492', '194221', '113450', '113476']\n",
    "segundoLic2 = ['113034', '116319', '191027', '150649', '194280']\n",
    "terceiroLic2 = ['115045', '113093', '117366', '117889']\n",
    "\n",
    "primeiroEngComp =['113034', '113093', '113476', '117528', '118001', '118010']\n",
    "segundoEngComp = ['118028', '118036', '113042', '115045', '116319']\n",
    "terceiroEngComp =['113051', '117242', '170054', '201600', '206075']\n",
    "\n",
    "\n",
    "primeiroMec = ['114626', '114634', '118010', '113476', '113034', '118001', '168891']\n",
    "segundoMec = ['168891', '113093', '118028', '118036', '115045', '168874']\n",
    "terceiroMec = ['113051', '118044', '118052', '168769', '116319']\n",
    "\n",
    "primeiroRedes = ['113034', '113093', '118001', '118010', '167959']\n",
    "segundoRedes = ['113042', '115045', '118028', '118036', '169676']\n",
    "terceiroRedes = ['113051', '113301', '167983', '169749']\n",
    "\n",
    "\n",
    "undropableCol = [\"curso\",\"saiu\",\"Cotista\",\"Ra√ßa\",\"Sexo\",\"Tipo de Escola\"]#, 'Ingresso_unb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"aluno_quant_Materias_Media_nao_cotistas_0.csv\", index_col=0)\n",
    "df1 = pd.read_csv(\"aluno_quant_Materias_Media_nao_cotistas_1.csv\", index_col=0)\n",
    "df2 = pd.read_csv(\"aluno_quant_Materias_Media_nao_cotistas_2.csv\", index_col=0)\n",
    "df3 = pd.read_csv(\"aluno_quant_Materias_Media_nao_cotistas_3.csv\", index_col=0)\n",
    "df4 = pd.read_csv(\"aluno_quant_Materias_Media_nao_cotistas_4.csv\", index_col=0)\n",
    "df5 = pd.read_csv(\"aluno_quant_Materias_Media_nao_cotistas_5.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfComp = df0[undropableCol+primeiroLic1+segundoLic1+terceiroLic1].fillna(-1)\n",
    "dfRedes = df1[undropableCol+primeiroRedes+segundoRedes+terceiroRedes].fillna(-1)\n",
    "dfCic = df2[undropableCol+primeiroCiC+segundoCiC+terceiroCiC].fillna(-1) \n",
    "dfMec = df3[undropableCol+primeiroMec+segundoMec+terceiroMec].fillna(-1) \n",
    "dfEng = df4[undropableCol+primeiroEngComp+segundoEngComp+terceiroEngComp].fillna(-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA (df, currentLabel = 'saiu'):\n",
    "    data = (\n",
    "        df\n",
    "\n",
    "    )\n",
    "    \n",
    "    x = data.iloc[:].values\n",
    "    y = data[currentLabel].values\n",
    "\n",
    "    data[currentLabel]\n",
    "    numColors = len(data[currentLabel].unique())\n",
    "\n",
    "    sklearn_pca = sklearnPCA(n_components=2)\n",
    "\n",
    "    Y_sklearn = sklearn_pca.fit_transform(x)\n",
    "\n",
    "    cmap = get_cmap(numColors+1)\n",
    "    colorList = [cmap(i) for i in range(1, numColors+1)]\n",
    "\n",
    "\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for lab, col in zip(data[currentLabel].unique(),\n",
    "                            colorList):\n",
    "            plt.scatter(Y_sklearn[y==lab, 0],\n",
    "                        Y_sklearn[y==lab, 1],\n",
    "                        label=lab,\n",
    "                        c=col)\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatColor(color):\n",
    "    return 'rgb('+str(int(color[0]*255))+','+str(int(color[1]*255))+','+str(int(color[2]*255))+')'\n",
    "\n",
    "    \n",
    "def tsne(df, currentLabel = 'saiu'):\n",
    "    a = df\n",
    "    X = a.values\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "    \n",
    "    \n",
    "    data = a\n",
    "    Y_sklearn = X_embedded\n",
    "    y = data[currentLabel].values\n",
    "    numColors = len(data[currentLabel].unique())\n",
    "\n",
    "    cmap = get_cmap(numColors+1)\n",
    "    colorList = [cmap(i) for i in range(1, numColors+1)]\n",
    "\n",
    "\n",
    "    traceArr = []\n",
    "    for lab, col in zip(data[currentLabel].unique(),\n",
    "                        colorList):\n",
    "        \n",
    "        trace1 = go.Scatter(\n",
    "            x=Y_sklearn[y==lab, 0],\n",
    "            y=Y_sklearn[y==lab, 1],\n",
    "#             z=Y_sklearn[y==lab, 2],\n",
    "            mode='markers',\n",
    "            name = str(lab),\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=formatColor(col),\n",
    "                opacity=0.8\n",
    "            )\n",
    "        )\n",
    "        traceArr.append(trace1)\n",
    "\n",
    "    data = traceArr\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='3d-scatter-colorscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw2dFrame(a, X_embedded, 'saiu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = a[a[\"saiu\"]!=0]\n",
    "# y = a[\"saiu\"]\n",
    "# X = a.drop([\"saiu\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def knn (df, currentLabel = 'saiu'):\n",
    "    a = df[df[currentLabel]!=0]\n",
    "    y = a[currentLabel]\n",
    "    X = a.drop([currentLabel], axis=1)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test = scaler.transform(X_test)  \n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=2)  \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "def knncv (df, currentLabel = 'saiu'):\n",
    "    a = df[df[currentLabel]!=0]\n",
    "    y = a[currentLabel]\n",
    "    X = a.drop([currentLabel], axis=1)\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "#     print(skf.split(X, y))\n",
    "    array = []\n",
    "    for train, test in skf.split(X, y):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        X_train = X[train]\n",
    "        X_test = X[test]\n",
    "        y_train = y[train]\n",
    "        y_test = y[test]\n",
    "        scaler = StandardScaler()  \n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)  \n",
    "        X_test = scaler.transform(X_test)  \n",
    "\n",
    "        classifier = KNeighborsClassifier(n_neighbors=2)  \n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        print(confusion_matrix(y_test, y_pred))  \n",
    "        print(classification_report(y_test, y_pred))\n",
    "        array.append(classification_report(y_test, y_pred, output_dict = True))\n",
    "#         print(X[train])\n",
    "    print(array[1]['-1']['precision'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137  13]\n",
      " [ 61  99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.91      0.79       150\n",
      "           1       0.88      0.62      0.73       160\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       310\n",
      "   macro avg       0.79      0.77      0.76       310\n",
      "weighted avg       0.79      0.76      0.76       310\n",
      "\n",
      "[[135  15]\n",
      " [ 26 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.90      0.87       150\n",
      "           1       0.90      0.84      0.87       160\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       310\n",
      "   macro avg       0.87      0.87      0.87       310\n",
      "weighted avg       0.87      0.87      0.87       310\n",
      "\n",
      "[[146   4]\n",
      " [ 38 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.97      0.87       150\n",
      "           1       0.97      0.76      0.85       160\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       310\n",
      "   macro avg       0.88      0.87      0.86       310\n",
      "weighted avg       0.88      0.86      0.86       310\n",
      "\n",
      "[[143   6]\n",
      " [ 37 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.96      0.87       149\n",
      "           1       0.95      0.77      0.85       160\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       309\n",
      "   macro avg       0.87      0.86      0.86       309\n",
      "weighted avg       0.88      0.86      0.86       309\n",
      "\n",
      "[[142   7]\n",
      " [ 47 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.95      0.84       149\n",
      "           1       0.94      0.71      0.81       160\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       309\n",
      "   macro avg       0.85      0.83      0.82       309\n",
      "weighted avg       0.85      0.83      0.82       309\n",
      "\n",
      "0.8385093167701864\n"
     ]
    }
   ],
   "source": [
    "knncv(dfCic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()  \n",
    "# scaler.fit(X_train)\n",
    "\n",
    "# X_train = scaler.transform(X_train)  \n",
    "# X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = KNeighborsClassifier(n_neighbors=2)  \n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# print(confusion_matrix(y_test, y_pred))  \n",
    "# print(classification_report(y_test, y_pred))\n",
    "# knn(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correla√ß√£o heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrMat(df):\n",
    "    f = (df).corr('spearman')\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.heatmap(f, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "def gradent(df, currentLabel = 'saiu'):\n",
    "    params = {\n",
    "        'n_estimators': 150,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'criterion': 'friedman_mse'\n",
    "    }\n",
    "    \n",
    "    a = df[df[currentLabel]!=0]\n",
    "    y = a[currentLabel]\n",
    "    X = a.drop([currentLabel], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    \n",
    "    gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "    gradient_boosting_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = gradient_boosting_regressor.predict(X_test)\n",
    "    y_pred = (y_pred>0)*1\n",
    "    y_pred = np.array([x if x !=0 else -1 for x in y_pred])\n",
    "#     print (y_pred)\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "def gradentcv(df, currentLabel = 'saiu'):\n",
    "    params = {\n",
    "        'n_estimators': 150,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'criterion': 'friedman_mse'\n",
    "    }\n",
    "    \n",
    "    a = df[df[currentLabel]!=0]\n",
    "    y = a[currentLabel]\n",
    "    X = a.drop([currentLabel], axis=1)\n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    \n",
    "    array = []\n",
    "    for train, test in skf.split(X, y):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        X_train = X[train]\n",
    "        X_test = X[test]\n",
    "        y_train = y[train]\n",
    "        y_test = y[test]\n",
    "        \n",
    "#         scaler = StandardScaler()  \n",
    "#         scaler.fit(X_train)\n",
    "\n",
    "#         X_train = scaler.transform(X_train)  \n",
    "#         X_test = scaler.transform(X_test)  \n",
    "\n",
    "        \n",
    "        gradient_boosting_regressor = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "        gradient_boosting_regressor.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = gradient_boosting_regressor.predict(X_test)\n",
    "        y_pred = (y_pred>0)*1\n",
    "        y_pred = np.array([x if x !=0 else -1 for x in y_pred])\n",
    "    #     print (y_pred)\n",
    "        print(confusion_matrix(y_test, y_pred))  \n",
    "        print(classification_report(y_test, y_pred))\n",
    "        array.append(classification_report(y_test, y_pred, output_dict = True))\n",
    "#         print(X[train])\n",
    "    print(array[1]['-1']['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47  13]\n",
      " [ 23 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.78      0.72        60\n",
      "           1       0.89      0.83      0.86       132\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       192\n",
      "   macro avg       0.78      0.80      0.79       192\n",
      "weighted avg       0.82      0.81      0.82       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradent(dfComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38  17]\n",
      " [ 24 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.69      0.65        55\n",
      "           1       0.87      0.82      0.85       137\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       192\n",
      "   macro avg       0.74      0.76      0.75       192\n",
      "weighted avg       0.80      0.79      0.79       192\n",
      "\n",
      "[[ 28  27]\n",
      " [ 16 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.51      0.57        55\n",
      "           1       0.82      0.88      0.85       137\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       192\n",
      "   macro avg       0.73      0.70      0.71       192\n",
      "weighted avg       0.77      0.78      0.77       192\n",
      "\n",
      "[[ 31  24]\n",
      " [  4 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.56      0.69        55\n",
      "           1       0.85      0.97      0.90       137\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       192\n",
      "   macro avg       0.87      0.77      0.80       192\n",
      "weighted avg       0.86      0.85      0.84       192\n",
      "\n",
      "[[ 44  11]\n",
      " [ 16 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.80      0.77        55\n",
      "           1       0.92      0.88      0.90       137\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       192\n",
      "   macro avg       0.82      0.84      0.83       192\n",
      "weighted avg       0.86      0.86      0.86       192\n",
      "\n",
      "[[ 37  18]\n",
      " [ 26 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.67      0.63        55\n",
      "           1       0.86      0.81      0.83       137\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       192\n",
      "   macro avg       0.72      0.74      0.73       192\n",
      "weighted avg       0.78      0.77      0.78       192\n",
      "\n",
      "0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "gradentcv(dfComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(dfComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(dfComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(dfComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(dfComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradent(dfComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(dfRedes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(dfRedes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(dfRedes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(dfRedes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(dfMec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(dfMec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn(dfMec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(dfMec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(dfCic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(dfCic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn(dfCic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(dfCic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(dfEng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(dfEng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn(dfEng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(dfEng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
